"use client";

import { useState, useRef, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Progress } from '@/components/ui/progress';
import { Badge } from '@/components/ui/badge';
import { 
  Mic, 
  MicOff, 
  Volume2, 
  VolumeX, 
  CheckCircle, 
  XCircle,
  Loader2,
  Settings,
  Headphones
} from 'lucide-react';

interface VoiceLoginProps {
  onLoginSuccess?: (result: any) => void;
  onError?: (error: string) => void;
}

interface VoiceAnalysis {
  confidence: number;
  text: string;
  language: string;
  emotion: string;
  isUserVoice: boolean;
}

export function VoiceLogin({ onLoginSuccess, onError }: VoiceLoginProps) {
  const [isListening, setIsListening] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [confidence, setConfidence] = useState(0);
  const [volume, setVolume] = useState(0);
  const [isMuted, setIsMuted] = useState(false);
  const [analysis, setAnalysis] = useState<VoiceAnalysis | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [audioLevel, setAudioLevel] = useState<number[]>([]);
  
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  useEffect(() => {
    if ('webkitSpeechRecognition' in window) {
      recognitionRef.current = new (window as any).webkitSpeechRecognition();
    } else if ('SpeechRecognition' in window) {
      recognitionRef.current = new (window as any).SpeechRecognition();
    }

    if (recognitionRef.current) {
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = 'zh-CN';
      recognitionRef.current.maxAlternatives = 3;

      recognitionRef.current.onstart = () => {
        setIsListening(true);
        setError(null);
        startAudioVisualization();
      };

      recognitionRef.current.onresult = (event: any) => {
        let finalTranscript = '';
        let interimTranscript = '';
        let maxConfidence = 0;

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          const confidence = event.results[i][0].confidence;
          
          maxConfidence = Math.max(maxConfidence, confidence);
          
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }

        setTranscript(finalTranscript || interimTranscript);
        setConfidence(Math.round(maxConfidence * 100));
      };

      recognitionRef.current.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setError(`è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`);
        setIsListening(false);
        stopAudioVisualization();
      };

      recognitionRef.current.onend = () => {
        setIsListening(false);
        stopAudioVisualization();
        
        if (transcript) {
          processVoiceLogin();
        }
      };
    }
  }, [transcript]);

  // éŸ³é¢‘å¯è§†åŒ–
  const startAudioVisualization = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      audioContextRef.current = audioContext;
      
      const analyser = audioContext.createAnalyser();
      analyserRef.current = analyser;
      
      const microphone = audioContext.createMediaStreamSource(stream);
      microphone.connect(analyser);
      
      analyser.fftSize = 256;
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      
      const updateAudioLevel = () => {
        if (!analyserRef.current || !isListening) return;
        
        analyserRef.current.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((a, b) => a + b, 0) / bufferLength;
        setVolume(Math.round(average));
        
        // æ›´æ–°éŸ³é¢‘æ³¢å½¢
        const levels = Array.from(dataArray).slice(0, 20);
        setAudioLevel(levels);
        
        animationFrameRef.current = requestAnimationFrame(updateAudioLevel);
      };
      
      updateAudioLevel();
    } catch (err) {
      console.error('Error accessing microphone:', err);
      setError('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
    }
  };

  const stopAudioVisualization = () => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
    }
  };

  // å¼€å§‹/åœæ­¢å½•éŸ³
  const toggleRecording = () => {
    if (isListening) {
      recognitionRef.current?.stop();
      setIsListening(false);
      stopAudioVisualization();
    } else {
      setTranscript('');
      setError(null);
      recognitionRef.current?.start();
    }
  };

  // å¤„ç†è¯­éŸ³ç™»å½•
  const processVoiceLogin = async () => {
    setIsProcessing(true);
    
    try {
      // æ¨¡æ‹Ÿè¯­éŸ³åˆ†æ
      const mockAnalysis: VoiceAnalysis = {
        confidence: confidence,
        text: transcript,
        language: 'zh-CN',
        emotion: getEmotionFromText(transcript),
        isUserVoice: Math.random() > 0.2 // 80% æ¦‚ç‡è®¤ä¸ºæ˜¯ç”¨æˆ·å£°éŸ³
      };
      
      setAnalysis(mockAnalysis);
      
      // æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
      await new Promise(resolve => setTimeout(resolve, 2000));
      
      if (mockAnalysis.isUserVoice && mockAnalysis.confidence > 70) {
        // æ¨¡æ‹ŸæˆåŠŸçš„ç™»å½•
        const mockResult = {
          success: true,
          user: {
            id: 'voice-user-123',
            email: 'tset123qq@example.com',
            name: 'è¯­éŸ³ç”¨æˆ·',
            credits: 10
          }
        };
        
        onLoginSuccess?.(mockResult);
      } else {
        throw new Error('è¯­éŸ³éªŒè¯å¤±è´¥ï¼Œè¯·é‡è¯•');
      }
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'è¯­éŸ³ç™»å½•å¤±è´¥';
      setError(errorMessage);
      onError?.(errorMessage);
    } finally {
      setIsProcessing(false);
    }
  };

  // ä»æ–‡æœ¬åˆ†ææƒ…ç»ª
  const getEmotionFromText = (text: string): string => {
    const positiveWords = ['å¥½', 'æ˜¯', 'å¯¹', 'å¯ä»¥', 'ç¡®è®¤', 'ç™»å½•', 'è¿›å…¥'];
    const negativeWords = ['ä¸', 'é”™', 'é”™è¯¯', 'å¤±è´¥', 'å–æ¶ˆ'];
    
    const hasPositive = positiveWords.some(word => text.includes(word));
    const hasNegative = negativeWords.some(word => text.includes(word));
    
    if (hasPositive && !hasNegative) return 'positive';
    if (hasNegative) return 'negative';
    return 'neutral';
  };

  // è·å–æƒ…ç»ªé¢œè‰²
  const getEmotionColor = (emotion: string) => {
    switch (emotion) {
      case 'positive': return 'text-green-600 bg-green-100';
      case 'negative': return 'text-red-600 bg-red-100';
      default: return 'text-gray-600 bg-gray-100';
    }
  };

  // è·å–æƒ…ç»ªå›¾æ ‡
  const getEmotionIcon = (emotion: string) => {
    switch (emotion) {
      case 'positive': return 'ğŸ˜Š';
      case 'negative': return 'ğŸ˜';
      default: return 'ğŸ˜';
    }
  };

  return (
    <Card className="w-full max-w-md mx-auto">
      <CardHeader className="text-center">
        <CardTitle className="flex items-center justify-center gap-2">
          <Mic className="h-6 w-6 text-blue-500" />
          è¯­éŸ³ç™»å½•
        </CardTitle>
        <p className="text-sm text-gray-600">
          è¯´å‡ºæ‚¨çš„ç™»å½•ä¿¡æ¯è¿›è¡Œèº«ä»½éªŒè¯
        </p>
      </CardHeader>

      <CardContent className="space-y-6">
        {/* éŸ³é¢‘å¯è§†åŒ– */}
        <div className="space-y-4">
          <div className="flex items-center justify-center">
            <div className={`w-24 h-24 rounded-full flex items-center justify-center transition-all duration-300 ${
              isListening ? 'bg-red-100 animate-pulse' : 'bg-blue-100'
            }`}>
              {isListening ? (
                <MicOff className="h-8 w-8 text-red-500" />
              ) : (
                <Mic className="h-8 w-8 text-blue-500" />
              )}
            </div>
          </div>

          {/* éŸ³é‡æŒ‡ç¤ºå™¨ */}
          <div className="space-y-2">
            <div className="flex items-center justify-between">
              <span className="text-sm text-gray-600">éŸ³é‡</span>
              <div className="flex items-center gap-2">
                {isMuted ? <VolumeX className="h-4 w-4" /> : <Volume2 className="h-4 w-4" />}
                <span className="text-sm">{volume}%</span>
              </div>
            </div>
            <Progress value={volume} className="h-2" />
          </div>

          {/* éŸ³é¢‘æ³¢å½¢ */}
          {isListening && audioLevel.length > 0 && (
            <div className="flex items-center justify-center gap-1 h-8">
              {audioLevel.map((level, index) => (
                <div
                  key={index}
                  className="bg-blue-500 rounded-sm transition-all duration-100"
                  style={{
                    width: '3px',
                    height: `${Math.max(4, (level / 255) * 32)}px`,
                    opacity: level > 50 ? 1 : 0.5
                  }}
                />
              ))}
            </div>
          )}
        </div>

        {/* æ§åˆ¶æŒ‰é’® */}
        <div className="flex gap-3">
          <Button
            onClick={toggleRecording}
            disabled={isProcessing}
            className={`flex-1 ${isListening ? 'bg-red-500 hover:bg-red-600' : ''}`}
          >
            {isListening ? (
              <>
                <MicOff className="mr-2 h-4 w-4" />
                åœæ­¢å½•éŸ³
              </>
            ) : (
              <>
                <Mic className="mr-2 h-4 w-4" />
                å¼€å§‹å½•éŸ³
              </>
            )}
          </Button>
          
          <Button
            variant="outline"
            onClick={() => setIsMuted(!isMuted)}
            className="px-3"
          >
            {isMuted ? <VolumeX className="h-4 w-4" /> : <Volume2 className="h-4 w-4" />}
          </Button>
        </div>

        {/* è¯†åˆ«ç»“æœ */}
        {transcript && (
          <div className="space-y-3">
            <div className="p-3 bg-gray-50 rounded-lg">
              <div className="flex items-center justify-between mb-2">
                <span className="text-sm font-medium">è¯†åˆ«ç»“æœ</span>
                <Badge variant="outline">ç½®ä¿¡åº¦: {confidence}%</Badge>
              </div>
              <p className="text-sm text-gray-700">{transcript}</p>
            </div>

            {/* è¯­éŸ³åˆ†æç»“æœ */}
            {analysis && (
              <div className="space-y-2">
                <div className="flex items-center gap-2">
                  <span className="text-sm font-medium">è¯­éŸ³åˆ†æ:</span>
                  <Badge className={`${getEmotionColor(analysis.emotion)} flex items-center gap-1`}>
                    <span>{getEmotionIcon(analysis.emotion)}</span>
                    {analysis.emotion}
                  </Badge>
                </div>
                
                <div className="grid grid-cols-2 gap-4 text-xs">
                  <div>
                    <span className="text-gray-600">è¯­è¨€:</span>
                    <span className="ml-1 font-medium">{analysis.language}</span>
                  </div>
                  <div>
                    <span className="text-gray-600">éªŒè¯:</span>
                    <span className="ml-1 font-medium">
                      {analysis.isUserVoice ? (
                        <span className="text-green-600 flex items-center gap-1">
                          <CheckCircle className="h-3 w-3" />
                          é€šè¿‡
                        </span>
                      ) : (
                        <span className="text-red-600 flex items-center gap-1">
                          <XCircle className="h-3 w-3" />
                          å¤±è´¥
                        </span>
                      )}
                    </span>
                  </div>
                </div>
              </div>
            )}
          </div>
        )}

        {/* å¤„ç†çŠ¶æ€ */}
        {isProcessing && (
          <div className="flex items-center justify-center gap-2 p-4 bg-blue-50 rounded-lg">
            <Loader2 className="h-4 w-4 animate-spin text-blue-500" />
            <span className="text-sm text-blue-700">æ­£åœ¨å¤„ç†è¯­éŸ³æ•°æ®...</span>
          </div>
        )}

        {/* é”™è¯¯ä¿¡æ¯ */}
        {error && (
          <div className="p-3 bg-red-50 border border-red-200 rounded-md">
            <div className="flex items-center gap-2">
              <XCircle className="h-4 w-4 text-red-500" />
              <p className="text-sm text-red-600">{error}</p>
            </div>
          </div>
        )}

        {/* ä½¿ç”¨æç¤º */}
        <div className="p-3 bg-blue-50 border border-blue-200 rounded-md">
          <div className="flex items-start gap-2">
            <Headphones className="h-4 w-4 text-blue-500 mt-0.5" />
            <div className="text-sm text-blue-700">
              <p className="font-medium mb-1">ä½¿ç”¨æç¤º:</p>
              <ul className="space-y-1 text-xs">
                <li>â€¢ è¯·æ¸…æ™°åœ°è¯´å‡ºæ‚¨çš„é‚®ç®±åœ°å€</li>
                <li>â€¢ ç¡®ä¿åœ¨å®‰é™çš„ç¯å¢ƒä¸­è¿›è¡Œå½•éŸ³</li>
                <li>â€¢ è·ç¦»éº¦å…‹é£20-30å˜ç±³æ•ˆæœæœ€ä½³</li>
                <li>â€¢ æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡è¯­éŸ³è¯†åˆ«</li>
              </ul>
            </div>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}
